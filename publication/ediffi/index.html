<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.3" />
    <meta name="author" content="Xun Huang">
    <meta name="description" content="Research Scientist">

    <link rel="stylesheet" href="https://www.xunhuang.me/css/highlight.min.css">
    <link rel="stylesheet" href="https://www.xunhuang.me/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://www.xunhuang.me/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://www.xunhuang.me/css/academicons.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="https://www.xunhuang.me/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://www.xunhuang.me/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://www.xunhuang.me/publication/ediffi/">

    <title>eDiff-I: Text-to-Image Diffusion Models with Ensemble of Expert Denoisers | Xun Huang</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://www.xunhuang.me/">Xun Huang</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://www.xunhuang.me/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://www.xunhuang.me/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://www.xunhuang.me/#teaching">Teaching</a></li>
                
                <li class="nav-item"><a href="https://www.xunhuang.me/#services">Services</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <div class="pub" itemscope itemtype="http://schema.org/CreativeWork">
        <div class="pub-title">
            <h1 itemprop="name">eDiff-I: Text-to-Image Diffusion Models with Ensemble of Expert Denoisers</h1>
            <span class="pub-authors" itemprop="author">
                
                Yogesh Balaji, Seungjun Nah, <b>Xun Huang</b>, Arash Vahdat, Jiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, Ming-Yu Liu
                
            </span>
            <span class="pull-right">
                
<div class="share-box">
    <ul class="share">
        <li>
            <a class="facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwww.xunhuang.me%2fpublication%2fediffi%2f" target="_blank">
                <i class="fa fa-facebook"></i>
            </a>
        </li>
        <li>
            <a class="twitter" href="https://twitter.com/intent/tweet?text=eDiff-I%3a%20Text-to-Image%20Diffusion%20Models%20with%20Ensemble%20of%20Expert%20Denoisers&amp;url=https%3a%2f%2fwww.xunhuang.me%2fpublication%2fediffi%2f" target="_blank">
                <i class="fa fa-twitter"></i>
            </a>
        </li>
        <li>
            <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwww.xunhuang.me%2fpublication%2fediffi%2f&amp;title=eDiff-I%3a%20Text-to-Image%20Diffusion%20Models%20with%20Ensemble%20of%20Expert%20Denoisers" target="_blank">
                <i class="fa fa-linkedin"></i>
            </a>
        </li>
        <li>
            <a class="weibo" href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fwww.xunhuang.me%2fpublication%2fediffi%2f&amp;title=eDiff-I%3a%20Text-to-Image%20Diffusion%20Models%20with%20Ensemble%20of%20Expert%20Denoisers" target="_blank">
                <i class="fa fa-weibo"></i>
            </a>
        </li>
        <li>
            <a class="email" href="mailto:?subject=eDiff-I%3a%20Text-to-Image%20Diffusion%20Models%20with%20Ensemble%20of%20Expert%20Denoisers&amp;body=https%3a%2f%2fwww.xunhuang.me%2fpublication%2fediffi%2f">
                <i class="fa fa-envelope"></i>
            </a>
        </li>
    </ul>
</div>


            </span>
        </div>

        
        <img src="https://www.xunhuang.me/img/ediffi.jpg" class="pub-banner" itemprop="image">
        

        <h3>Abstract</h3>
        <p class="pub-abstract" itemprop="text">Large-scale diffusion-based generative models have led to breakthroughs in text-conditioned high-resolution image synthesis. Starting from random noise, such text-to-image diffusion models gradually synthesize images in an iterative fashion while conditioning on text prompts. We find that their synthesis behavior qualitatively changes throughout this process: Early in sampling, generation strongly relies on the text prompt to generate text-aligned content, while later, the text conditioning is almost entirely ignored. This suggests that sharing model parameters throughout the entire generation process may not be ideal. Therefore, in contrast to existing works, we propose to train an ensemble of text-to-image diffusion models specialized for different synthesis stages. To maintain training efficiency, we initially train a single model, which is then split into specialized models that are trained for the specific stages of the iterative generation process. Our ensemble of diffusion models, called eDiff-I, results in improved text alignment while maintaining the same inference computation cost and preserving high visual quality, outperforming previous large-scale text-to-image diffusion models on the standard benchmark. In addition, we train our model to exploit a variety of embeddings for conditioning, including the T5 text, CLIP text, and CLIP image embeddings. We show that these different embeddings lead to different behaviors. Notably, the CLIP image embedding allows an intuitive way of transferring the style of a reference image to the target text-to-image output. Lastly, we show a technique that enables eDiff-I&#39;s &#34;paint-with-words&#34; capability. A user can select the word in the input text and paint it in a canvas to control the output, which is very handy for crafting the desired image in mind.</p>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
                    <div class="col-xs-12 col-sm-9">arXiv 2022</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
                    <div class="col-xs-12 col-sm-9" itemprop="datePublished">November, 2022</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row" style="padding-top: 10px">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
                    <div class="col-xs-12 col-sm-9">

                        




<a class="btn btn-primary btn-outline" href="https://arxiv.org/pdf/2211.01324.pdf">PDF</a>







<a class="btn btn-primary btn-outline" href="https://arxiv.org/abs/2211.01324">Arxiv</a>

<a class="btn btn-primary btn-outline" href="https://www.xunhuang.me/publications/ediffi_bib.txt">BibTex</a>

<a class="btn btn-primary btn-outline" href="https://research.nvidia.com/labs/dir/eDiff-I">Website</a>



                    </div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="space-below"></div>

        <div class="article-style"></div>

    </div>

    <nav>
    <ul class="pager">
        
        <li class="previous"><a href="https://www.xunhuang.me/publication/poegan/"><span aria-hidden="true">&larr;</span> Multimodal Conditional Image Synthesis with Product-of-Experts GANs</a></li>
        

        
        <li class="next"><a href="https://www.xunhuang.me/publication/magic3d/">Magic3D: High-Resolution Text-to-3D Content Creation <span aria-hidden="true">&rarr;</span></a></li>
        
    </ul>
</nav>


</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">


            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://www.xunhuang.me/js/jquery-1.12.3.min.js"></script>
        <script src="https://www.xunhuang.me/js/bootstrap.min.js"></script>
        <script src="https://www.xunhuang.me/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-83050038-1', 'auto');
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

